{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "from copy import deepcopy\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA EXTRACTION\n",
    "data=pd.read_csv('/Users/michaelfilletti/Desktop/Uni/AI/Machine Learning/Assignment/Datasets/Absenteeism_at_work_AAA/Absenteeism_at_work.csv',sep=';')\n",
    "# Get one hot encoding of columns B\n",
    "a=['Reason for absence', 'Month of absence', 'Day of the week', 'Seasons', 'Education', 'Disciplinary failure', 'Social drinker', 'Social smoker']\n",
    "\n",
    "#ONE HOT ENCODING\n",
    "for i in range(0,len(a)):\n",
    "    one_hot = pd.get_dummies(data[a[i]])\n",
    "    data = data.drop(a[i],axis = 1)\n",
    "    data = data.join(one_hot)\n",
    "    s=a[i]\n",
    "    for j in range(0,np.shape(one_hot)[1]+1):\n",
    "        data.rename(columns={j:a[i]+str(j)}, inplace=True)\n",
    "\n",
    "#FEATURE SELECTION - PCC\n",
    "data2=data.drop(['ID', 'Absenteeism time in hours'], axis=1)\n",
    "y = data.iloc[:,12].values\n",
    "N=np.shape(data)[0]\n",
    "sY=np.sum(data['Absenteeism time in hours'].values)\n",
    "sY2=np.sum(np.square(data['Absenteeism time in hours'].values))\n",
    "PCC=np.zeros(np.shape(data2)[1])\n",
    "for i in range(0,np.shape(data2)[1]):\n",
    "    var=data2.iloc[:,i].values\n",
    "    sXY=np.sum(np.multiply(var, y))\n",
    "    sX=np.sum(var)\n",
    "    sX2=np.sum(np.square(var))\n",
    "    data.iloc[:,i]\n",
    "    PCC[i]=abs(N*sXY-(sX*sY))/np.sqrt((N*sX2-sX**2)*(N*sY2-sY**2))\n",
    "ind=np.argsort(-PCC)\n",
    "\n",
    "\n",
    "selected_features=15\n",
    "index=ind[0:selected_features]\n",
    "X=data2.iloc[:,index]\n",
    "\n",
    "normalized_X=(X-X.mean())/X.std() #normalized X\n",
    "ydf=pd.DataFrame(y,columns=['y'])\n",
    "dataset=pd.concat([normalized_X, ydf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMO STRUCTURE\n",
    "#Declaration of variables and various kernel options (lin or rbf)\n",
    "class SMOStructure:\n",
    "    # init the structure with parameters\n",
    "    def __init__(self, X, y, C, Cst, toler, kernel, gamma, epsilon, r, d):\n",
    "        self.X = np.mat(X) #independent data inputted by user\n",
    "        self.y = np.mat(y).T #dependent data inputted by user\n",
    "        self.y1=0 #y value of corresponding index\n",
    "        self.chi = 0 #chi value\n",
    "        self.C = C #inputted by user\n",
    "        self.Cst = Cst #inputted by user\n",
    "        self.epsilon = epsilon #inputted by user\n",
    "        self.tol = toler #inputted by user\n",
    "        self.gamma=gamma #inputted by user (used for rbf, poly and sigmoid)\n",
    "        if gamma<=0:\n",
    "            pass\n",
    "        self.r = r #inputted by user (used for poly and sigmoid)\n",
    "        self.d = d #inputted by user (used for poly)\n",
    "        self.test=0 #dummy variable used to debug\n",
    "        self.kernel = kernel #inputted by user\n",
    "        self.m = np.shape(X)[0] #number of rows of training set\n",
    "        self.n = np.shape(X)[1] #number of cols of training set\n",
    "        self.alphas = np.mat(np.zeros((self.m, 1))) #Initial value of alpha paras\n",
    "        self.alphast = np.mat(np.zeros((self.m, 1))) #Initial value of alpha paras\n",
    "        self.beta = 0 #Initial beta value\n",
    "        self.r1=0 #Initial KKT condn value\n",
    "        self.b = 0 #Initial value of bias para\n",
    "        self.e_cache = np.mat(np.zeros(self.m)).T #Error cache: holds memory of error\n",
    "        self.K = np.mat(np.zeros((self.m, self.m)))\n",
    "        self.gamma1=0\n",
    "        # init kernel cache matrix: lin or rbf\n",
    "        if kernel == 'lin':\n",
    "            self.K = self.X * self.X.T\n",
    "        elif kernel == 'rbf':\n",
    "            self.K = np.mat(np.zeros((self.m, self.m)))\n",
    "            for i in range(self.m):\n",
    "                for j in range(self.m):\n",
    "                    self.K[i, j] = (self.X[i] - self.X[j]) * (self.X[i] - self.X[j]).T\n",
    "                    self.K[i, j] = np.exp(self.K[i, j] * (-1 * self.gamma))\n",
    "        elif kernel == 'poly':\n",
    "            self.K = (self.gamma * self.X * self.X.T + self.r)**self.d\n",
    "        elif kernel == 'sigmoid':\n",
    "            self.K = np.tanh(self.gamma * self.X * self.X.T + self.r)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function takestep\n",
    "#This is the algorithm for REGRESSION\n",
    "def take_step(i1, i2, smo):\n",
    "    \n",
    "    #Declaring variables\n",
    "    alpha1 = smo.alphas[i1]\n",
    "    alphast1 = smo.alphast[i1]\n",
    "    y1 = smo.y[i1]\n",
    "    total=0\n",
    "    for j in range(0,len(smo.X)):\n",
    "        total += (smo.alphas[i1] - smo.alphast[i1]) * smo.K[j,i1]\n",
    "    E1 = total + smo.b - y1 #f(x)-y\n",
    "    \n",
    "    #Declaring other variables \n",
    "    alpha2 = smo.alphas[i2]\n",
    "    alphast2 = smo.alphast[i2]\n",
    "    y2 = smo.y[i2]\n",
    "    E2 = smo.e_cache[i2]\n",
    "    smo.gamma1=(alpha1-alphast1)+(alpha2-alphast2)\n",
    "    \n",
    "    #Defining L,H,l,h\n",
    "    L = max(smo.gamma1-smo.C, -smo.Cst)\n",
    "    H = min(smo.gamma1+smo.Cst, smo.C)\n",
    "    if L == H:\n",
    "        return 0\n",
    "    l=min(smo.gamma1,0)\n",
    "    h=max(smo.gamma1,0)\n",
    "    \n",
    "    #Chi (kernel sum and subtraction)\n",
    "    smo.chi = smo.K[i1, i1] + smo.K[i2, i2] - 2*smo.K[i1, i2]\n",
    "    #Updating a2\n",
    "    if smo.chi > 0:\n",
    "        #a2 = alpha2 + y2*(E1-E2)/chi\n",
    "        beta0 = (alpha1-alphast1) + (E1-E2)/smo.chi\n",
    "        betap = beta0 - (2*smo.epsilon/smo.chi)\n",
    "        betan = beta0 + (2*smo.epsilon/smo.chi)\n",
    "        \n",
    "        beta=max(min(beta0,h),l) #Let beta be the point that lies within the interval (i.e. beta0, h or l)\n",
    "        if beta == h: #If beta is h, this means beta0 it is not in I0, so we move to betap\n",
    "            beta = max(min(betap,H),h) #Again, we find the point within the interval\n",
    "        elif beta == l: #If beta is l, this means it is not in I0\n",
    "            beta = max(min(betan,l),L) #We find the point within the interval\n",
    "    elif (E1-E2) < 0:\n",
    "        beta=h\n",
    "        if (E1-E2)+2*smo.epsilon < 0:\n",
    "            beta=H\n",
    "    else:\n",
    "        beta=l\n",
    "        if (E1-E2)-2*smo.epsilon > 0:\n",
    "            beta=L\n",
    "    \n",
    "    #Converging condition\n",
    "    #if abs(beta-(alpha1-alphast1)) < smo.epsilon*(smo.epsilon+abs(beta)+alpha1+alphast1):\n",
    "    #    return 0\n",
    "    \n",
    "    #Updating alpha\n",
    "    alpha1 = max(beta,0)\n",
    "    alphast1 = max(-beta,0)\n",
    "    alpha2 = max(0,smo.gamma1-beta)\n",
    "    alphast2=max(0,beta-smo.gamma1)\n",
    "    \n",
    "    #Updating b\n",
    "    if alpha1 > 0 and alpha1 < smo.C:\n",
    "        bnew =  y1 - (smo.K[i1, i1] * (smo.alphas[i1] - smo.alphast[i1])) - smo.epsilon\n",
    "    elif alphast1 > 0 and alphast1 < smo.Cst:\n",
    "        bnew = y1 - (smo.K[i1, i1] * (smo.alphas[i1] - smo.alphast[i1])) + smo.epsilon\n",
    "    else:\n",
    "        b1 = y1 - (smo.K[i1, i1] * (smo.alphas[i1] - smo.alphast[i1])) - smo.epsilon\n",
    "        b2 = y1 - (smo.K[i1, i1] * (smo.alphas[i1] - smo.alphast[i1])) + smo.epsilon\n",
    "        bnew = (b1 + b2) / 2\n",
    "    \n",
    "    #Declaring the new b, a1 and a2\n",
    "    smo.b = bnew\n",
    "    smo.alphas[i1] = alpha1\n",
    "    smo.alphast[i1] = alphast1\n",
    "    smo.alphas[i2] = alpha2\n",
    "    smo.alphast[i2] = alphast2\n",
    "    \n",
    "    \n",
    "    #Updating cache (y_1-f(x_1), y_2-f(x_2),...)\n",
    "    total=0\n",
    "    for i in range(smo.m):\n",
    "        if (smo.alphas[i] > 0) and (smo.alphas[i] < smo.C):\n",
    "            for j in range(0,len(smo.X)):\n",
    "                total += (smo.alphas[i] - smo.alphast[i])*smo.K[j,i]\n",
    "            smo.e_cache[i] = total + smo.b - smo.y[i] #Error\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing Heuristics\n",
    "def examine_example(i1, smo):\n",
    "    #Declare variables based on i1\n",
    "    smo.y1 = smo.y[i1]\n",
    "    alpha1 = smo.alphas[i1]\n",
    "    alphast1 = smo.alphast[i1]\n",
    "    H=min(smo.gamma1+smo.Cst,smo.C) #initial value for H\n",
    "    total=0\n",
    "    \n",
    "    for j in range(0,len(smo.X)):\n",
    "        total += (smo.alphas[i1] - smo.alphast[i1])*smo.K[j,i1]\n",
    "    E1 = total + smo.b - smo.y1\n",
    "    #Set elements of e_cache\n",
    "    smo.e_cache[i1] = E1\n",
    "    #r1 = alpha1*max(0,E1+smo.epsilon)+alphast1*max(0,-E1+smo.epsilon)+(smo.C-alpha1)*max(0,E1+smo.epsilon)+(smo.Cst-alphast1)*max(0,E1-smo.epsilon) \n",
    "    #r1 represents KKT\n",
    "    smo.r1=H*alpha1*max(0,E1+smo.epsilon)+H*alphast1*max(0,smo.epsilon-E1)+H*(smo.C-alpha1)*max(0,smo.epsilon-E1)+H*(smo.Cst-alphast1)*max(0,E1-smo.epsilon)\n",
    "    \n",
    "    #---Identifying if KKT conditions are satisfied\n",
    "    #if r1 lies outside tolerance region and \n",
    "    if(smo.r1>smo.tol):\n",
    "        #Only if there is a nonbound and nonzero alpha, we find j\n",
    "        if (smo.alphas[i1] < smo.C) or (smo.alphas[i1] > 0):\n",
    "            \n",
    "            # heuristic 1: find the max deltaE to know which j to select\n",
    "            max_delta_E = 0\n",
    "            i2 = -1\n",
    "            #Cover all training set\n",
    "            for i in range(smo.m):\n",
    "                #If it lies within the bound\n",
    "                if smo.alphas[i] > 0 and smo.alphas[i] < smo.C:\n",
    "                    E2 = smo.e_cache[i]\n",
    "                    delta_E = abs(E1 - E2)\n",
    "                    if delta_E > max_delta_E:\n",
    "                        max_delta_E = delta_E #update max_delta_E\n",
    "                        i2 = i #Let i2 be the i with the greatest max_delta_E\n",
    "            #if i1 >= 0:\n",
    "            if take_step(i1, i2, smo)==1:\n",
    "                return 1\n",
    "        \n",
    "        # heuristic 2: find the suitable i2 on border at random\n",
    "        #---Loop over all non zero and non C alpha\n",
    "        random_index = np.random.permutation(smo.m) #Randomly index training set\n",
    "        for i in random_index:\n",
    "            if smo.alphas[i] > 0 and smo.alphas[i] < smo.C:\n",
    "                if take_step(i1, i, smo)==1:\n",
    "                    return 1\n",
    "            \n",
    "        \n",
    "        # heuristic 3: find the suitable i1 at random on all alphas\n",
    "        #---Loop over all possible i\n",
    "        #random_index = set(np.random.permutation(smo.m)) - set(indices)\n",
    "        for i in random_index:\n",
    "            if take_step(i1, i, smo)==1:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main SMO Process\n",
    "#Set number of iterations here, and sets how the program works\n",
    "def SMORegression(smo, max_iter=20):\n",
    "    #Set variables\n",
    "    num_changed = 0\n",
    "    examine_all = 1\n",
    "    passes = 0\n",
    "    #Sets number of iterations to loop\n",
    "    #Bounds number of passes the program can make\n",
    "    while(passes <= max_iter):\n",
    "        num_changed = 0 #Reset num_changed to 0\n",
    "        \n",
    "        if (examine_all == 1): #If examine_all is set to 1\n",
    "            for i1 in range(smo.m): #Loop i1 over whole range\n",
    "                num_changed += examine_example(i1, smo) #Run examine_example\n",
    "        else:\n",
    "            for i1 in range(smo.m): #If examine_all is not set to 1\n",
    "                if (smo.alphas[i1] > 0) and (smo.alphas[i1] < smo.C): #Only carry out for those not on bound\n",
    "                    num_changed += examine_example(i1, smo) #Run examine_example\n",
    "        \n",
    "        if (num_changed == 0):\n",
    "            passes += 1 #Increment passes by 1 if num_changed is 0\n",
    "        \n",
    "        if (examine_all == 1):\n",
    "            examine_all = 0\n",
    "        elif (num_changed == 0):\n",
    "            examine_all = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------K-FOLD CROSS-VALIDATION---------\n",
    "#Split a dataset into k folds\n",
    "#the original sample is randomly partitioned into k equal sized subsamples. \n",
    "#Of the k subsamples, a single subsample is retained as the validation data \n",
    "#for testing the model, and the remaining k âˆ’ 1 subsamples are used as training data. \n",
    "#The cross-validation process is then repeated k times (the folds),\n",
    "#with each of the k subsamples used exactly once as the validation data.\n",
    "def cross_validation_split(data, n_folds):\n",
    "    dataset_split = list() #Create list containing dataset split\n",
    "    dataset_copy = list(data) #Convert data to list\n",
    "    fold_size = int(len(data) / n_folds) #Fold size = total length of data / no of folds\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size: #Adding data into each fold\n",
    "            index = random.randrange(0,len(dataset_copy)) #generate random number to input into fold\n",
    "            fold.append(dataset_copy.pop(index)) #input corresponding data point into fold\n",
    "        dataset_split.append(fold) #append to split data\n",
    "    return dataset_split\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, n_folds, C, Cst, toler, kernel, gamma, epsilon, r, d):\n",
    "    #folds are the subsamples used to train and validate model\n",
    "    folds = cross_validation_split(dataset, n_folds) #call previous function\n",
    "    scores = list() #list of scores\n",
    "    i=0\n",
    "    #for each subsample\n",
    "    for i in range(0,n_folds):\n",
    "        #create a copy of the data\n",
    "        test_set=folds[i]\n",
    "        train_set = deepcopy(folds) #Training set\n",
    "        #remove the given subsample\n",
    "        train_set.pop(i) #Remove one of the folds\n",
    "        train_set = sum(train_set, []) #Make two dimensional\n",
    "        #init a test set\n",
    "        #test_set = list() #empty list\n",
    "        \n",
    "        #add each row in a given subsample to the test set\n",
    "        #for row in fold:\n",
    "        #    row_copy = list(row)\n",
    "        #    test_set.append(row_copy) #appending each row to the test set\n",
    "        #    row_copy[-1] = None\n",
    "        \n",
    "        #get predicted labels\n",
    "        ytrain=[item[-1] for item in train_set]\n",
    "        xtrain=[item[:-2] for item in train_set]\n",
    "        ytest=[item[-1] for item in test_set]\n",
    "        xtest=[item[:-2] for item in test_set]\n",
    "        smo = SMOStructure(xtrain, ytrain, C, Cst, toler, kernel, gamma, epsilon, r, d) #applying the algorithm\n",
    "        SMORegression(smo)\n",
    "        K=np.mat(np.zeros((len(train_set), len(test_set))))\n",
    "        ypred=np.zeros(len(test_set))\n",
    "        \n",
    "        xtrainm=np.concatenate(xtrain).reshape(len(train_set),np.shape(dataset)[1]-2)\n",
    "        xtestm=np.concatenate(xtest).reshape(np.shape(dataset)[1]-2,len(test_set))\n",
    "        K = (xtrainm).dot(xtestm)\n",
    "        for i in range(0,len(test_set)):\n",
    "            total=0\n",
    "            for j in range(0,len(train_set)):\n",
    "                total += (smo.alphas[j] - smo.alphast[j])*K[j,i]\n",
    "            ypred[i] = total + smo.b\n",
    "            #get actual labels\n",
    "        \n",
    "        #actual = ytest #get y values\n",
    "        #compare accuracy\n",
    "        accuracy = mean_squared_error(ytest, ypred) #compare y values to actual values (MSE)\n",
    "        #add it to scores list, for each fold\n",
    "        scores.append(accuracy)\n",
    "        #print(scores)\n",
    "    #return all accuracy scores\n",
    "    return (scores, np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([113440727.86272976, 255.20731707317069, 323230650.6073509],\n",
       " 145557211.22579923)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUNNING THE ALGORITHM (using k-fold cross-validation)\n",
    "cross_validation_split(np.array(dataset), 3)\n",
    "evaluate_algorithm(np.array(dataset), n_folds=3, C=1000, Cst=1000, toler=0.001, kernel='rbf', gamma=1, epsilon=10, r=10, d=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of sklearn Model: 213.97230559991613\n",
      "Average KCV score 190.5349938966664\n"
     ]
    }
   ],
   "source": [
    "#PACKAGE PERFORMANCE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "clf = SVR(C=0.01, epsilon=0.01,kernel='rbf',gamma=5)\n",
    "clf.fit(X_train, y_train) \n",
    "ypredskl=clf.predict(X_test)\n",
    "msesk=mean_squared_error(y_test, ypredskl)\n",
    "print('MSE of sklearn Model:',msesk)\n",
    "\n",
    "#Using K-fold Cross Validation\n",
    "scores = cross_validate(clf, X, y, cv=3,scoring='neg_mean_squared_error',return_train_score=True)\n",
    "print('Average KCV score',-np.mean(pd.DataFrame(scores).iloc[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
